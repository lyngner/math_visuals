name: Deploy infrastructure

permissions:
  contents: read
  id-token: write

on:
  pull_request:
    branches:
      - main
    types:
      - closed
  workflow_dispatch:
    inputs:
      cloudfront_invalidation_paths:
        description: "Space-separated list of paths to invalidate (defaults to /*)"
        required: false
        default: "/*"

jobs:
  deploy-iac:
    name: Deploy CloudFormation stacks
    runs-on: ubuntu-latest
    if: ${{ github.event_name != 'pull_request' || github.event.pull_request.merged }}
    env:
      # Required GitHub secrets for AWS access and stack configuration
      AWS_REGION: ${{ secrets.AWS_REGION }}
      AWS_IAC_ROLE_ARN: ${{ secrets.AWS_IAC_ROLE_ARN }}
      STATIC_SITE_BUCKET_NAME: ${{ secrets.STATIC_SITE_BUCKET_NAME }}
      STATIC_SITE_CLOUDFRONT_DISTRIBUTION_ID: ${{ secrets.STATIC_SITE_CLOUDFRONT_DISTRIBUTION_ID }}
      STATIC_SITE_API_DOMAIN: ${{ secrets.STATIC_SITE_API_DOMAIN }}
      STATIC_SITE_API_ORIGIN_PATH: ${{ secrets.STATIC_SITE_API_ORIGIN_PATH }}
      STATIC_SITE_CLOUDFRONT_PRICE_CLASS: ${{ secrets.STATIC_SITE_CLOUDFRONT_PRICE_CLASS }}
      API_ARTIFACT_BUCKET: ${{ secrets.API_ARTIFACT_BUCKET }}
      API_ARTIFACT_KEY: ${{ secrets.API_ARTIFACT_KEY }}
      API_STAGE_NAME: ${{ secrets.API_STAGE_NAME }}
      CLOUDFRONT_INVALIDATION_PATHS: ${{ github.event.inputs.cloudfront_invalidation_paths || secrets.CLOUDFRONT_INVALIDATION_PATHS || '/*' }}
      # Stack names and defaults
      STATIC_STACK_NAME: math-visuals-static
      API_STACK_NAME: math-visuals-api
      DATA_STACK_NAME: math-visuals-data
      DATA_ENVIRONMENT_NAME: prod
      SHARED_PARAMETERS_STACK_NAME: math-visuals-shared
      SKIP_EXAMPLES_SEEDING: "true"
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20

      - name: Install workspace dependencies
        run: npm ci

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          role-to-assume: ${{ env.AWS_IAC_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Compute Lambda artefact key
        run: |
          set -euo pipefail
          base_key="${API_ARTIFACT_KEY:-lambda/api-lambda.zip}"
          base_without_zip="${base_key%.zip}"
          new_key="${base_without_zip}-${GITHUB_SHA}.zip"
          echo "LAMBDA_CODE_KEY=$new_key" >> "$GITHUB_ENV"

      - name: Build Lambda artefact
        run: |
          set -euo pipefail
          scripts/package-api-lambda.sh

      - name: Upload Lambda artefact to S3
        run: |
          set -euo pipefail
          artefact_path="infra/api/api-lambda.zip"
          aws s3 cp "$artefact_path" "s3://$API_ARTIFACT_BUCKET/$LAMBDA_CODE_KEY"
          version_id=$(aws s3api head-object --bucket "$API_ARTIFACT_BUCKET" --key "$LAMBDA_CODE_KEY" --query 'VersionId' --output text 2>/dev/null || true)
          if [ -n "${version_id:-}" ] && [ "$version_id" != "None" ]; then
            echo "LAMBDA_CODE_VERSION=$version_id" >> "$GITHUB_ENV"
          fi

      - name: Deploy data stack
        env:
          REDIS_PASSWORD: ${{ secrets.REDIS_PASSWORD }}
        run: |
          aws cloudformation deploy \
            --stack-name "$DATA_STACK_NAME" \
            --template-file infra/data/template.yaml \
            --capabilities CAPABILITY_IAM \
            --parameter-overrides \
              EnvironmentName=$DATA_ENVIRONMENT_NAME \
              SharedParametersStackName=$SHARED_PARAMETERS_STACK_NAME \
              RedisAuthToken=$REDIS_PASSWORD

      - name: Sync shared Redis connection parameters
        env:
          REDIS_ENDPOINT: ${{ secrets.REDIS_ENDPOINT }}
          REDIS_PORT: ${{ secrets.REDIS_PORT }}
          REDIS_PASSWORD: ${{ secrets.REDIS_PASSWORD }}
        run: |
          set -euo pipefail

          if [ -z "${REDIS_ENDPOINT:-}" ] || [ -z "${REDIS_PORT:-}" ] || [ -z "${REDIS_PASSWORD:-}" ]; then
            echo "Missing REDIS_* secrets. Make sure REDIS_ENDPOINT, REDIS_PORT and REDIS_PASSWORD are configured." >&2
            exit 1
          fi

          get_output() {
            local stack_name="$1"
            local output_key="$2"
            aws cloudformation describe-stacks \
              --stack-name "$stack_name" \
              --query "Stacks[0].Outputs[?OutputKey=='${output_key}'].OutputValue" \
              --output text
          }

          REDIS_PASSWORD_SECRET_NAME=$(get_output "$SHARED_PARAMETERS_STACK_NAME" RedisPasswordSecretName)
          REDIS_ENDPOINT_PARAMETER_NAME=$(get_output "$SHARED_PARAMETERS_STACK_NAME" RedisEndpointParameterName)
          REDIS_PORT_PARAMETER_NAME=$(get_output "$SHARED_PARAMETERS_STACK_NAME" RedisPortParameterName)

          if [ -z "$REDIS_PASSWORD_SECRET_NAME" ] || [ "$REDIS_PASSWORD_SECRET_NAME" == "None" ]; then
            echo "Unable to resolve RedisPasswordSecretName output from stack $SHARED_PARAMETERS_STACK_NAME" >&2
            exit 1
          fi

          if [ -z "$REDIS_ENDPOINT_PARAMETER_NAME" ] || [ "$REDIS_ENDPOINT_PARAMETER_NAME" == "None" ]; then
            echo "Unable to resolve RedisEndpointParameterName output from stack $SHARED_PARAMETERS_STACK_NAME" >&2
            exit 1
          fi

          if [ -z "$REDIS_PORT_PARAMETER_NAME" ] || [ "$REDIS_PORT_PARAMETER_NAME" == "None" ]; then
            echo "Unable to resolve RedisPortParameterName output from stack $SHARED_PARAMETERS_STACK_NAME" >&2
            exit 1
          fi

          SECRET_STRING=$(python - <<'PY'
import json, os
print(json.dumps({"authToken": os.environ["REDIS_PASSWORD"]}))
PY
)

          aws secretsmanager put-secret-value \
            --secret-id "$REDIS_PASSWORD_SECRET_NAME" \
            --secret-string "$SECRET_STRING"

          aws ssm put-parameter \
            --name "$REDIS_ENDPOINT_PARAMETER_NAME" \
            --type String \
            --value "$REDIS_ENDPOINT" \
            --overwrite

          aws ssm put-parameter \
            --name "$REDIS_PORT_PARAMETER_NAME" \
            --type String \
            --value "$REDIS_PORT" \
            --overwrite

      - name: Deploy API stack
        run: |
          set -euo pipefail
          PARAM_OVERRIDES="LambdaCodeS3Bucket=$API_ARTIFACT_BUCKET LambdaCodeS3Key=$LAMBDA_CODE_KEY StageName=$API_STAGE_NAME"
          if [ -n "${LAMBDA_CODE_VERSION:-}" ]; then
            PARAM_OVERRIDES="$PARAM_OVERRIDES LambdaCodeS3ObjectVersion=$LAMBDA_CODE_VERSION"
          fi
          PARAM_OVERRIDES="$PARAM_OVERRIDES DataStackName=$DATA_STACK_NAME SharedParametersStackName=$SHARED_PARAMETERS_STACK_NAME"
          aws cloudformation deploy \
            --stack-name "$API_STACK_NAME" \
            --template-file infra/api/template.yaml \
            --capabilities CAPABILITY_IAM CAPABILITY_AUTO_EXPAND \
            --parameter-overrides $PARAM_OVERRIDES

      - name: Resolve API endpoint for static site
        run: |
          set -euo pipefail
          endpoint=$(aws cloudformation describe-stacks \
            --stack-name "$API_STACK_NAME" \
            --query "Stacks[0].Outputs[?OutputKey=='ApiEndpoint'].OutputValue" \
            --output text)
          if [ -z "$endpoint" ] || [ "$endpoint" = "None" ]; then
            echo "Fant ikke ApiEndpoint-output fra $API_STACK_NAME" >&2
            exit 1
          fi
          endpoint="${endpoint%%/}"
          echo "API_ENDPOINT_URL=$endpoint" >> "$GITHUB_ENV"
          python - <<'PY' >> "$GITHUB_ENV"
import os
from urllib.parse import urlparse

endpoint = os.environ["API_ENDPOINT_URL"].rstrip("/")
parsed = urlparse(endpoint)
domain = parsed.netloc
path = parsed.path or "/"
if not path.startswith('/'):
    path = '/' + path
examples = endpoint.rstrip('/') + '/api/examples'
print(f"API_GATEWAY_DOMAIN_NAME={domain}")
print(f"API_GATEWAY_ORIGIN_PATH={path}")
print(f"API_EXAMPLES_URL={examples}")
PY

      - name: Run examples API health check
        run: |
          set -euo pipefail
          npm run check-examples-api -- --url="${API_EXAMPLES_URL}"

      - name: Materialize examples dataset for seeding
        env:
          EXAMPLES_SEED_JSON: ${{ secrets.EXAMPLES_SEED_JSON }}
          EXAMPLES_SEED_JSON_PROD: ${{ secrets.EXAMPLES_SEED_JSON_PROD }}
          EXAMPLES_SEED_JSON_DEV: ${{ secrets.EXAMPLES_SEED_JSON_DEV }}
          EXAMPLES_SEED_JSON_PREVIEW: ${{ secrets.EXAMPLES_SEED_JSON_PREVIEW }}
        run: |
          set -euo pipefail
          env_name="${DATA_ENVIRONMENT_NAME:-prod}"

          select_dataset() {
            local selected="$1"
            case "$env_name" in
              prod) echo "${EXAMPLES_SEED_JSON_PROD:-$selected}" ;;
              dev) echo "${EXAMPLES_SEED_JSON_DEV:-$selected}" ;;
              preview) echo "${EXAMPLES_SEED_JSON_PREVIEW:-$selected}" ;;
              *) echo "$selected" ;;
            esac
          }

          dataset=$(select_dataset "${EXAMPLES_SEED_JSON:-}" )

          if [ -z "$dataset" ]; then
            echo "Ingen EXAMPLES_SEED_JSON*-secret er konfigurert for miljÃ¸et '$env_name'. Hopper over seeding." >&2
            echo "SKIP_EXAMPLES_SEEDING=true" >> "$GITHUB_ENV"
            exit 0
          fi

          mkdir -p docs
          printf '%s' "$dataset" > docs/examples-seed.json
          echo "SKIP_EXAMPLES_SEEDING=false" >> "$GITHUB_ENV"

      - name: Validate examples dataset (--dry-run)
        if: env.SKIP_EXAMPLES_SEEDING != 'true'
        env:
          REGION: ${{ env.AWS_REGION }}
          DATA_STACK: ${{ env.DATA_STACK_NAME }}
          API_URL: ${{ env.API_EXAMPLES_URL }}
        run: |
          set -euo pipefail
          bash scripts/cloudshell-seed-examples.sh --dataset=docs/examples-seed.json --dry-run

      - name: Seed examples dataset
        if: env.SKIP_EXAMPLES_SEEDING != 'true'
        env:
          REGION: ${{ env.AWS_REGION }}
          DATA_STACK: ${{ env.DATA_STACK_NAME }}
          API_URL: ${{ env.API_EXAMPLES_URL }}
        run: |
          set -euo pipefail
          bash scripts/cloudshell-seed-examples.sh --dataset=docs/examples-seed.json

      - name: Deploy static site stack
        run: |
          set -euo pipefail
          api_domain="${STATIC_SITE_API_DOMAIN:-$API_GATEWAY_DOMAIN_NAME}"
          api_origin_path="${STATIC_SITE_API_ORIGIN_PATH:-$API_GATEWAY_ORIGIN_PATH}"
          if [ -z "$api_domain" ]; then
            echo "Fant ikke API-domene for CloudFront-oppsettet" >&2
            exit 1
          fi
          if [ -z "$api_origin_path" ]; then
            api_origin_path="/"
          fi
          aws cloudformation deploy \
            --stack-name "$STATIC_STACK_NAME" \
            --template-file infra/static-site/template.yaml \
            --capabilities CAPABILITY_IAM \
            --parameter-overrides \
              SiteBucketName=$STATIC_SITE_BUCKET_NAME \
              ApiGatewayDomainName=$api_domain \
              ApiGatewayOriginPath=$api_origin_path \
              CloudFrontPriceClass=$STATIC_SITE_CLOUDFRONT_PRICE_CLASS \
              SharedParametersStackName=$SHARED_PARAMETERS_STACK_NAME

      - name: Build and upload static assets
        env:
          SITE_BUCKET_NAME: ${{ env.STATIC_SITE_BUCKET_NAME }}
        run: |
          set -euo pipefail
          npm run build
          aws s3 sync public/ "s3://$SITE_BUCKET_NAME/" --delete

      - name: Invalidate CloudFront cache
        if: ${{ env.STATIC_SITE_CLOUDFRONT_DISTRIBUTION_ID != '' }}
        run: |
          PATHS="${CLOUDFRONT_INVALIDATION_PATHS:-/*}"
          echo "Using invalidation paths: $PATHS"
          aws cloudfront create-invalidation \
            --distribution-id "$STATIC_SITE_CLOUDFRONT_DISTRIBUTION_ID" \
            --paths $PATHS
